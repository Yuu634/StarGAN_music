## ğŸ—ï¸ Model Architecture
<p align="center">
  <img src="assets/revise_model.png" alt="Amadeus architecture" width="600">
</p>


## ãƒ¢ãƒ‡ãƒ«ä¿®æ­£ç‚¹
å…¥åŠ›è­œé¢å…¨ä½“ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‰ã«concatã—ã¦ç”Ÿæˆ
â‡’è­œé¢ç·¨æ›²ãƒ¢ãƒ‡ãƒ«ã®å®Ÿç¾


## ã‚³ãƒ¼ãƒ‰ä¿®æ­£éƒ¨åˆ†
### Amadeus_app_EN.py
- generate_with_text_prompt
å…¥åŠ›è­œé¢ã®éŸ³ç¬¦å±æ€§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ—å…¥åŠ›
```python
file_path = "dataset/represented_data/tuneidx/tuneidx_test/nb8/sample.npz"  # èª­ã¿ãŸã„ npz ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
data = np.load(file_path)
input_note = data['arr_0']
input_note = torch.tensor(input_note, dtype=torch.long).to(device)
```

### model_zoo.py
- AmadeusModelAutoregressiveWrapperã‚¯ãƒ©ã‚¹ã®generate
å…¥åŠ›è­œé¢ã®åŸ‹ã‚è¾¼ã¿ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã®concat
```python
if input_note is not None:
    # input_note shape: [batch_size, num_notes, 8] or [num_notes, 8]
    if len(input_note.shape) == 2:
      input_note = input_note.unsqueeze(0)  # [1, num_notes, 8]
    
    # Add positional encoding
    note_embedding = self.net.input_embedder(input_note) + self.net.pos_enc(input_note)
    note_embedding = self.net.emb_dropout(note_embedding)
    
    # === Concatenate with text context ===
    if context is not None:
      # context: [batch_size, text_seq_len, dim]
      # note_embedding: [batch_size, num_notes, dim]
      context = torch.cat([note_embedding, context], dim=1)  # [batch_size, text_seq_len + num_notes, dim]
    else:
      context = note_embedding
```
